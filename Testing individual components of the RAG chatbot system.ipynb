{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ab2f6a-fd8d-4c94-b461-a68ba4c1aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: Yes\n",
      "API key starts with: sk-proj-...\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to the Python path\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is loaded\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"API key loaded: {'Yes' if api_key else 'No'}\")\n",
    "print(f\"API key starts with: {api_key[:8]}...\" if api_key else \"No API key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c288b2fd-ee29-4bdc-a440-275c666fa48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 documents:\n",
      "- RAG Chatbot Project Plan.docx (word)\n",
      "- Amazon-com-Inc-2023-Annual-Report.pdf (pdf)\n",
      "- yearly_product_sales_comparison_with_three_column_bar_graph_slide01-3614560801.jpg (image)\n"
     ]
    }
   ],
   "source": [
    "#  Initialize Document Processor\n",
    "from src.document_processor.loader import DocumentLoader\n",
    "from src.document_processor.text_extractor import TextExtractor\n",
    "from src.document_processor.chunker import TextChunker\n",
    "\n",
    "# Initialize components\n",
    "loader = DocumentLoader()\n",
    "extractor = TextExtractor()\n",
    "chunker = TextChunker()\n",
    "\n",
    "# List available documents\n",
    "files = loader.get_file_list()\n",
    "print(f\"Found {len(files)} documents:\")\n",
    "for file in files:\n",
    "    print(f\"- {file['name']} ({file['type']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faecf552-9828-40c7-a661-ccd55e32890b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 12:10:56,795 - src.document_processor.text_extractor - INFO - Extracting text from /Users/mdwaquarahmad/Documents/fortune500-rag/uploads/RAG Chatbot Project Plan.docx of type word\n",
      "2025-04-25 12:10:56,812 - src.document_processor.text_extractor - INFO - Extracted 136 text blocks from /Users/mdwaquarahmad/Documents/fortune500-rag/uploads/RAG Chatbot Project Plan.docx\n",
      "2025-04-25 12:10:56,813 - src.document_processor.chunker - INFO - Created 136 chunks from 136 text blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RAG Chatbot Project Plan.docx...\n",
      "Extracted 136 text blocks\n",
      "\n",
      "Sample text block:\n",
      "Text: RAG Chatbot Project Plan...\n",
      "Metadata: {'source': 'RAG Chatbot Project Plan.docx', 'company': 'RAG Chatbot Project Plan', 'paragraph': 1, 'section': 'body'}\n",
      "\n",
      "Created 136 chunks\n",
      "\n",
      "Sample chunk:\n",
      "Text: RAG Chatbot Project Plan...\n",
      "Metadata: {'source': 'RAG Chatbot Project Plan.docx', 'company': 'RAG Chatbot Project Plan', 'paragraph': 1, 'section': 'body', 'chunk': 1, 'total_chunks': 1}\n"
     ]
    }
   ],
   "source": [
    "# Process a specific document\n",
    "if files:\n",
    "    # Take the first file for testing\n",
    "    test_file = files[0]\n",
    "    print(f\"Processing {test_file['name']}...\")\n",
    "    \n",
    "    # Extract text\n",
    "    text_blocks = extractor.extract_text(test_file)\n",
    "    print(f\"Extracted {len(text_blocks)} text blocks\")\n",
    "    \n",
    "    # Show a sample\n",
    "    if text_blocks:\n",
    "        print(\"\\nSample text block:\")\n",
    "        print(f\"Text: {text_blocks[0]['text'][:200]}...\")\n",
    "        print(f\"Metadata: {text_blocks[0]['metadata']}\")\n",
    "    \n",
    "    # Chunk text\n",
    "    chunks = chunker.chunk_documents(text_blocks)\n",
    "    print(f\"\\nCreated {len(chunks)} chunks\")\n",
    "    \n",
    "    # Show a sample chunk\n",
    "    if chunks:\n",
    "        print(\"\\nSample chunk:\")\n",
    "        print(f\"Text: {chunks[0]['text'][:200]}...\")\n",
    "        print(f\"Metadata: {chunks[0]['metadata']}\")\n",
    "else:\n",
    "    print(\"No documents found for processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279ffad7-06be-401e-a232-04003a98d1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 12:11:20,236 - src.vector_store.embeddings - INFO - Initialized embedding generator with model: text-embedding-3-small\n",
      "2025-04-25 12:11:20,363 - src.vector_store.store - INFO - Initialized Chroma collection: fortune500_docs\n",
      "/Users/mdwaquarahmad/Documents/fortune500-rag/src/vector_store/store.py:56: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  self.langchain_db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB stats: {'collection_name': 'fortune500_docs', 'document_count': 37693, 'path': '/Users/mdwaquarahmad/Documents/fortune500-rag/chroma_db'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize Vector Store\n",
    "from src.vector_store.embeddings import EmbeddingGenerator\n",
    "from src.vector_store.store import VectorStore\n",
    "\n",
    "# Initialize embedding generator\n",
    "embedding_generator = EmbeddingGenerator()\n",
    "\n",
    "# Initialize vector store\n",
    "vector_store = VectorStore(embedding_generator)\n",
    "\n",
    "# Get stats\n",
    "stats = vector_store.get_stats()\n",
    "print(f\"Vector DB stats: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ad8dc7-b10d-4ef3-ab6c-9696a12d3f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 136 chunks to vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 12:11:50,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 12:11:51,711 - src.vector_store.embeddings - INFO - Generated 136 embeddings\n",
      "2025-04-25 12:11:51,994 - src.vector_store.store - INFO - Added 136 documents to vector store\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 136 chunks with IDs: ['aebf693d-02d2-4049-98be-7a74ca7f23ef', '4c81b0a7-a83e-4ba7-a61c-e7118c350b6f', '5bf60538-0773-4026-b23b-d39ff20957d3']...\n",
      "Updated Vector DB stats: {'collection_name': 'fortune500_docs', 'document_count': 37829, 'path': '/Users/mdwaquarahmad/Documents/fortune500-rag/chroma_db'}\n"
     ]
    }
   ],
   "source": [
    "# Add Documents to Vector Store\n",
    "if 'chunks' in locals() and chunks:\n",
    "    # Add chunks to vector store\n",
    "    print(f\"Adding {len(chunks)} chunks to vector store...\")\n",
    "    doc_ids = vector_store.add_documents(chunks)\n",
    "    print(f\"Added {len(doc_ids)} chunks with IDs: {doc_ids[:3]}...\")\n",
    "    \n",
    "    # Get updated stats\n",
    "    stats = vector_store.get_stats()\n",
    "    print(f\"Updated Vector DB stats: {stats}\")\n",
    "else:\n",
    "    print(\"No chunks available to add to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a153f4bf-1469-45ab-89b6-386b69b6c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: 'What was Amazon's revenue in 2023?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 12:12:20,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 12:12:20,599 - src.vector_store.store - INFO - Found 5 results for query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 results\n",
      "\n",
      "Result 1 (score: 0.6782):\n",
      "Text: By segment, North\n",
      "America revenue increased 12% Y oY from $316B to $353B, International revenue grew 11% Y oY from\n",
      "$118B to $131B, and AWS revenue inc...\n",
      "Metadata: {'total_chunks': 10, 'company': 'Amazon com Inc 2023 Annual Report', 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf', 'chunk': 2, 'page': 2, 'total_pages': 92}\n",
      "\n",
      "Result 2 (score: 0.6782):\n",
      "Text: By segment, North\n",
      "America revenue increased 12% Y oY from $316B to $353B, International revenue grew 11% Y oY from\n",
      "$118B to $131B, and AWS revenue inc...\n",
      "Metadata: {'total_pages': 92, 'page': 2, 'company': 'Amazon com Inc 2023 Annual Report', 'total_chunks': 10, 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf', 'chunk': 2}\n",
      "\n",
      "Result 3 (score: 0.6782):\n",
      "Text: By segment, North\n",
      "America revenue increased 12% Y oY from $316B to $353B, International revenue grew 11% Y oY from\n",
      "$118B to $131B, and AWS revenue inc...\n",
      "Metadata: {'page': 2, 'total_pages': 92, 'total_chunks': 10, 'company': 'Amazon com Inc 2023 Annual Report', 'chunk': 2, 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Test search functionality\n",
    "test_query = \"What was Amazon's revenue in 2023?\"\n",
    "print(f\"Searching for: '{test_query}'\")\n",
    "\n",
    "search_results = vector_store.search(test_query)\n",
    "print(f\"Found {len(search_results)} results\")\n",
    "\n",
    "# Display top results\n",
    "for i, result in enumerate(search_results[:3]):\n",
    "    print(f\"\\nResult {i+1} (score: {result['score']:.4f}):\")\n",
    "    print(f\"Text: {result['text'][:150]}...\")\n",
    "    print(f\"Metadata: {result['metadata']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04de06a1-0974-4487-b7a2-5f1a43af4c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 12:14:54,947 - src.llm.response_generator - INFO - Initialized response generator with model: gpt-4o\n",
      "2025-04-25 12:14:54,947 - src.llm.response_generator - INFO - Generating response for query: What was Amazon's revenue in 2023?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 12:14:56,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-25 12:14:56,708 - src.llm.response_generator - INFO - Raw LLM response received: content=\"I don't have enough information to answer this question. The provided context includes revenue figures for Amazon's North America, International, and AWS segments, but it does not provide the total revenue for Amazon in 2023. Additional information on Amazon's total revenue would be needed to answer this question. The source of the provided information is Amazon.com Inc's 2023 Annual Report.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 1037, 'total_tokens': 1113, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BQ75r63po67FhMq0rMeKAOWBKz3N9', 'finish_reason': 'stop', 'logprobs': None} id='run-f7870d2c-38c2-46a1-9db3-addb3fa73800-0' usage_metadata={'input_tokens': 1037, 'output_tokens': 76, 'total_tokens': 1113, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "2025-04-25 12:14:56,710 - src.llm.response_generator - INFO - Response content type: <class 'str'>\n",
      "2025-04-25 12:14:56,711 - src.llm.response_generator - INFO - Response content: I don't have enough information to answer this question. The provided context includes revenue figur...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      "I don't have enough information to answer this question. The provided context includes revenue figures for Amazon's North America, International, and AWS segments, but it does not provide the total revenue for Amazon in 2023. Additional information on Amazon's total revenue would be needed to answer this question. The source of the provided information is Amazon.com Inc's 2023 Annual Report.\n",
      "\n",
      "Sources:\n",
      "Source 1: {'total_chunks': 10, 'company': 'Amazon com Inc 2023 Annual Report', 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf', 'chunk': 2, 'page': 2, 'total_pages': 92}\n",
      "Source 2: {'total_pages': 92, 'page': 2, 'company': 'Amazon com Inc 2023 Annual Report', 'total_chunks': 10, 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf', 'chunk': 2}\n",
      "Source 3: {'page': 2, 'total_pages': 92, 'total_chunks': 10, 'company': 'Amazon com Inc 2023 Annual Report', 'chunk': 2, 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf'}\n",
      "Source 4: {'page': 2, 'chunk': 2, 'total_chunks': 10, 'company': 'Amazon com Inc 2023 Annual Report', 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf', 'total_pages': 92}\n",
      "Source 5: {'total_chunks': 10, 'total_pages': 92, 'company': 'Amazon com Inc 2023 Annual Report', 'page': 2, 'chunk': 2, 'source': 'Amazon-com-Inc-2023-Annual-Report.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Test Response Generation\n",
    "from src.llm.response_generator import ResponseGenerator\n",
    "\n",
    "# Initialize response generator\n",
    "response_generator = ResponseGenerator()\n",
    "\n",
    "# Generate response\n",
    "if search_results:\n",
    "    print(\"Generating response...\")\n",
    "    result = response_generator.generate_response(test_query, search_results)\n",
    "    \n",
    "    print(\"\\nGenerated Response:\")\n",
    "    print(result[\"response\"])\n",
    "    \n",
    "    print(\"\\nSources:\")\n",
    "    for i, source in enumerate(result.get(\"sources\", [])):\n",
    "        print(f\"Source {i+1}: {source}\")\n",
    "else:\n",
    "    print(\"No search results available for response generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf84c39-6a8a-42e3-97d4-b8213b29df07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
